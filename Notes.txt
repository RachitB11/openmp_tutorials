Parallel computing allows us to go for the same throughput at a lower power.
Power  = Capacitance)(Voltage)^2(Frequency)
Concurrency: Multiple active agents are working at the same time.
Parallelism: Multiple programs are being executed at the same time.


OpenMP: API for writing multi-threaded applications
- Most of the constructs in OpenMP are
  #pragma omp construct[clause [clause]...]
    Eg: #pragma omp parallel num_threads(4)
- You need to #include<omp.h>
- It operates on structured blocks i.e. only on blocks of code with entry and exit
  you cannot jump in the middle.
- To set default number of threads $export OMP_NUM_THREADS=4
- To boil it down remember 4 things:
  - Its a multi threading shared address model
  - Unintended sharing of data causes race conditions
  - To control race conditions use synchronization to protect data conflicts
  - Change how data is accessed to minimize the need for synchronization

Shared memory computer:
- A computer is composed of multiple processing units that share an address space.
- There are 2 classes of this:
  - SMP (Symmetric multiprocessor): Equal time access for each processor and OS
    treats each processor equally.
  - NUMA (Non uniform Address Space multiprocessor): Not all memory is equal.
    Different regions have different access costs.
- Nearly all computers are NUMA now.
- Because of the cache architecture nowadays if the block of memory is close to the
  processor then it has much faster access than if it was far away. So nothing is
  truly SMP.
- Remember there is no constraint on threads running in order or even getting
  completed before another thread is begun executing. They interleave.
- Each thread has its own copy of the variables in the stack but they share the
  data, text and heap spaces in the computer.
- Unintended sharing of data causes race conditions. (When multiple threads
  simultaneously try to modify the shared memory)
- These race conditions cause getting different answers every-time. To control
  these use synchronization and protect data conflicts. Syncing is expensive,
  so make sure you're doing it right.

Fork join parallelism
- The main thread (id 0) is running serially and then forks into numerous threads.
- The master as well as the forked threads are called a team. These run parallely.
- The only way to create parallel threads in openmp is using the construct parallel.

Synchronization
- There are 2 main methods of synchronization in OpenMP:
  - Barrier: Each thread waits at the barrier till all arrive
  - Mutual Exclusion: A block of code can only be implemented by a single thread
- High level syncs: Critical, Atomic, Barrier, Ordered
- Low level syncs: Flush, Locks
- Barrier:
  #pragma omp parallel
  {
    int id = omp_get_thread_num();
    A[id] = big_cal1(id);
    // So here we are at a position where A needs to be used further. So a Barrier
    // is constructed to make sure all the threads are done working with A before
    // proceeding
    #pragma omp barrier
    {
      B[id] = big_cal2(id,A);
    }
  }
- Mutual Exclusion:
  float res;
  #pragma omp parallel
  {
    float B;
    int i, id,nthrds;
    id = omp_get_thread_num();
    nthrds = omp_get_num_threads();
    for(i=id;i<niters;i+=nthrds)
    {
      B=big_job(i);
      // Here we have this shared variable res being used by the threads. But we
      // don't want a race condition. So  to avoid this other threads are blocked
      // while one executes the code after the critical. This is mutual exclusion.
      #pragma omp critical
      {
        res+= consume(B);
      }
    }
  }
- Atomic: It is a hardware construct thats used only when it is available
  #pragma omp parallel
  {
    double tmp,B;
    B=DOIT();
    tmp = big_ugly(B);
    #pragma omp atomic
    {
      X+=tmp;
    }
  }

Worksharing
- Most of the stuff we have been doing is Single Program multiple data (SPMD)
  where the data is being divided and running parallely the same code. It may
  also be called SIMD (Single instruction multiple data)
- Work sharing spreads the work withing the structured code between the team.
- There's the loop construct, section/s construct, single construct etc.
- for loop construct:
  #pragma omp parallel
  {
    #pragma omp for
    for(i=0;i<N;i++)
    {
        Neat_stuff(i);
    }
  }
  When just a for loop is present in the structure then
  #pragma omp parallel for
  {
    for(i=0;i<N;i++)
    {
        Neat_stuff(i);
    }
  }
- As can be seen all of the complexities of SPMD code with having to deal with
  ids and nthreads is abstracted away.
- How do we deal out the chunks of data in the for loop needs to be defined and that
  is done via schedules. You can use the schedule after the omp for
  - schedule(static,[,chunk]) : Just deal out blocks of iterations of size "chunk"
    to each thread. It deals out evenly sized blocks if chunk is not defined.
  - schedule(dynamic,[,chunk]) : Maintain the blocks in a queue and grab "chunk" data
    at runtime. This is unlike static where stuff was allocated at compile time. This
    adjusts dynamically to how individual threads perform.
  - schedule(guided,[,chunk]) : Large block size initially and then go down to
    chunk size
  - schedule(runtime): Schedule and chunk size taken at runtime from the OMP_SCHEDULE variable.
  - schedule(auto): Schedule is left it upto runtime to choose.
- Use static when you know that the work per iteration is almost the same and use
  dynamic when the work per iteration is variable. It is a complex scheduler at runtime
- Useful tools omp_set_schedule(), omp_get_schedule() etc. Play around with these
  and figure out which one works best.
- Find the compute intensive loops and make sure you can structure it to be able to use pragma omp for
- Reduction clause:
  - Used when the value depends on the previous n iterations (Eg computing the average or factorial)
  - reduction(op:list)
  - Create a local copy of the variable in the list depending on the "op" like
    0 for addition and 1 for multiplication
  - Example: Calculating the average
  double ave=0.0, A[MAX]; int i;
  #pragma omp parallel for reduciton(+:ave)
  {
    for(i=0;i<MAX;i++)
    {
      ave+=A[i];
    }
  }
  ave/=MAX;

Advanced
- barriers and nowait:
  // Define the shared and private variables
  #pragma omp parallel shared(A,B,C) private(id)
  {
    id = omp_get_thread_num();
    A[id] = big_calc(id);

    // We want to use A further so need to setup a barrier
    #pragma omp barrier

    // C is going to be used further so we use the simple for. This for implicitly
    // states that the for loop must complete in all threads before moving further.
    #pragma omp for
      for(i=0;i<N;i++){C[i] = big_cal2(i,A)}

    // Here we explicitly add a no wait because B is not going to be used in the
    // thread. So there is no point blocking a thread.
    #pragma omp for nowait
      for(i=0;i<N;i++){B[i] = big_cal3(i,C)}

    A[id] = big_cal4(id);

    // Implicit barrier here because all the threads need to complete and merge
  }

- master:
  #pragma omp parallel
  {
    do_many_things();
    // This just says that just the master will do the things in this code block
    #pragma omp master
    {
      exchange_boundaries();
    }
    // Wait for the master to complete before moving on. So hence add the barrier
    #pragma omp barrier

    do_many_other_things();
  }

- single:
  #pragma omp parallel
  {
    do_many_things();
    // This just says that a single thread which is the first thread to access the
    // block will do this and there is also an implicit call for the other threads
    // to wait until this is executing. So no barrier was required here just like
    // the for construct.
    #pragma omp single
    {
      exchange_boundaries();
    }
    do_many_other_things();
  }

- section(s):
  #pragma omp parallel
  {
    // Here we define the sections which just means that one thread does the x section,
    // another the y section and so on
    #pragma_omp_sections
    {
      #pragma omp section
        x_calculation();
      #pragma omp section
        y_calculation();
      #pragma omp section
        z_calculation();
    }
  }

- locks:
  - The lowest form of achieving synchronization
  - Methods:
    - omp_init_lock()
    - omp_set_lock()
    - omp_unset_lock()
    - omp_destroy_lock()
    - omp_test_lock() (Checks if the lock is available)
  - While critical blocks the entire critical block. This allows us to selectively
    block and unblock
  - Eg: Suppose you were adding values to a histogram with a large bin size. If you
    used critical and blocked at every increment you would serialize the thing. Instead
    maintain a lock for each bin because the chances of multiple threads accessing the
    same bin is low (uncontended lock).
      // Initialize all the locks
      #pragma omp parallel for
      for(i=0;i<NBUCKETS;i++)
      {
        omp_init_lock(&hist_locks[i]);
        hist[i]=0;
      }

      // Use the vals to populate the histogram
      #pragma omp parallel for
      for(i=0;i<NVALS;i++)
      {
        ival = (int)sample(arr[i]);

        // Block only the bin which is being
        omp_set_lock(&hist_locks[ival])
          hist[ival]++;
        omp_unset_lock(&hist_locks[ival])
      }

      // Delete the locks
      #pragma omp parallel for
      for(i=0;i<NBUCKETS;i++)
      {
        omp_destory_lock(&hist_locks[i]);
      }

- Runtime library routines
  - Some examples:
    - omp_set_num_threads()
    - omp_get_num_threads()
    - omp_get_thread_num()
    - omp_get_max_threads() : Says I wont give you more threads than this
    - omp_in_parallel() : Calling in a parallel region or not?
    - omp_set_dynamic() : Depending on the load different parallel regions may get different number of threads
    - omp_get_dynamic() : Am I in dynamic mode or not?
    - omp_num_procs() : How many actual processors are there?
  - Example:
    #include <omp.h>
    void main()
    {
      int num_threads;

      // I care about the number of threads being used and I don't want the system
      // to dynamically keep on switching the number of threads on me. So I set
      // dynamic as off
      omp_set_dynamic(0);

      // Request the number of threads equal to the number of processors
      omp_set_num_threads(omp_num_procs());

      #pragma omp parallel
      {
        // Get the thread id
        int id = omp_get_thread_num();

        // Just one of threads execute this block while others wait.
        #pragma omp single
        {
          // Get the actual number of threads allocated
          // Need to do this in the parallel region. Thats when the threads
          // actually get allocated
          num_threads = omp_get_num_threads();
        }
        do_lots_of_stuff_id(id);
      }
    }

- Environment variables
  - Some examples:
    - OMP_NUM_THREADS : Number of threads being asked for
    - OMP_STACKSIZE : For each thread some amount of stack is allocated. So if your
      parallel constructs have beefy data structs then you wanna tell how much
      of the stack size you want allocated.
    - OMP_WAIT_POLICY : Suppose threads need to wait for a critical section to
      complete. You can define the wait policy as ACTIVE and have the thread consuming
      cpu cycles and constantly spinning till it gets the critical section or remain
      passive so that the thread is put to sleep i.e. PASSIVE. Sleeping and making it
      active is expensive. So if the threads are not anticipated to wait long then
      use ACTIVE else use PASSIVE.
    - OMP_PROC_BIND : So we have NUMA machines as discussed before. It is easier for
      a core to access a certain piece of memory than the other. So if we've carefully
      managed the cache we would want the threads being spawned to be binded to a core.
      A tradeoff is that the capability of the CPU to move the thread to another core
      if the current core is busy is restricted.

Data Environment
- OpenMP is a shared memory programming model. Most variables are shared by default.
- Global variables are shared among threads (file scope and static. Note that static varibales
  are defined in the code section)
- Stack variables are not shared. Heap variables are shared.
- NOTE: Do not take the stack heap terminology seriously stack variables defined outside
  the parallel construct may not be on the heap but are shared variables in the thread.
- You can change the storage attributes using these constructs:
  - SHARED
  - PRIVATE
  - FIRSTPRIVATE
  - LASTPRIVATE : In a loop construct the last value in the last iteration that
    the private variable should be copied to a global construct.
  - DEFAULT(PRIVATE|SHARED|NONE) : Default shared is what you get by default. None
    means that you need to explicitly the type of the variable (shared vs private).
    Private is not allowed in C. None is useful for debugging.

    void wrong()
    {
      int tmp =0;
      // This is buggy because there is no way to initialize the tmp variable once
      // its made PRIVATE. So on print this will give value 0 value of the global
      // copy.
      #pragma omp parallel for private(tmp)
        for(int i = 0; i<1000;++i) tmp+=j
      printf("%d\n",tmp);
    }

    void correct()
    {
      int incr =0;
      // This is fine because FIRSTPRIVATE is used which initializes it to the
      // global value which here is 0
      // Note that incr will not retain its value outside the scope though. Its
      // a private variable. So outside it is 0. Only shared variables are modified
      // in the code block
      #pragma omp parallel for firstprivate(incr)
        for(int i = 0; i<MAX;++i)
        {
          if(i%2==0) incr++;
          A[i] = incr;
        }
    }

    void sq2(int n, double *lastterm)
    {
      double x=0.0; int i;
      // This is fine because LASTPRIVATE will instruct the compiler to store the
      // very last value of x in the global variable x and hence lastterm will
      // contain a non 0 value.
      // Note that you can define firstprivate and lastprivate together
      #pragma omp parallel for lastprivate(x)
        for(i=0;i<n;i++)
        {
          x = a[i]*a[i]+b[i]*b[i];
          b[i] = sqrt(x);
        }
        *lastterm = x;
    }

Tasks
- Tasks are independent units of work.
- Composes of:
  - Code to execute
  - Data environment
  - Internal control variables
    - Keeps track of stuff like whats the default no. of threads. These were controlled
      by those runtime get set methods we learnt previously.
    - The binding of these variables happens to the tasks not the thread
- You setup tasks. It sort of maintains a queue and when threads become available
  it picks up the tasks one by one.
- Difference between tasks and sections
  https://stackoverflow.com/questions/13788638/difference-between-section-and-task-openmp
- Useful for understanding the task execution order
  https://openmp.org/wp-content/uploads/sc13.tasking.ruud.pdf


  #pragma omp parallel
  {
    // All the threads create this task (one per thread) and execute it
    // Theres a barrier to wait for everyone to complete the task
    #pragma omp task
    foo();
    #pragma omp barrier

    //Here just one thread is creating the tasks (one copy).
    //This does not mean that just one thread is gonna execute all these takss
    //The single thread is just setting up the task queue. Once all the tasks are in queue
    // the threads will start picking up the task.
    // Also since nowait was not added, everyone is gonna wait till the tasks are completed
    #pragma omp single
    {
      #pragma omp task
      bar();

      #pragma omp task
      bar2();
    }
  }

  // Assume this method is called within a single parallel space
  int fib(int n)
  {
    int x,y;
    if(n<2) return n;
    #pragma omp task shared(x)
      x = fib(n-1);
    #pragma omp task shared(y)
      y = fib(n-2);
    #pragma omp taskwait
      return x+y;
  }

  // GO through a list
  list ml;
  element* e;
  #pragma omp parallel

  // Here a single thread will queue up all the tasks and then once all the tasks
  // are added to the queue the threads will start picking up the tasks one by
  // one and complete them. Implicitly since it is a single and nowait is not
  // called, all threads stay here till all the tasks are completed.
  #pragma omp single
  {
    for(e=ml->first;e;e=e->next)
    #pragma omp task firstprivate(e)
      process(e);
  }
